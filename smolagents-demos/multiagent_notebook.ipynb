{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22ubrk7navwL"
      },
      "source": [
        "# Solving a complex task with a multi-agent hierarchy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdepXvxdavwN",
        "outputId": "ffcb09b2-2b55-4968-c101-d9ab0ef9402d"
      },
      "outputs": [],
      "source": [
        "!pip install 'smolagents[litellm]' matplotlib geopandas shapely kaleido -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
        "\n",
        "dotenv_path = os.path.join(parent_dir, \".env\")\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "# Set the token for Hugging Face API usage\n",
        "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dduWceHAavwO",
        "outputId": "597a7813-7b3d-43df-f044-cd6370949c23"
      },
      "outputs": [],
      "source": [
        "# We first make a tool to get the cargo plane transfer time.\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "from smolagents import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def calculate_cargo_travel_time(\n",
        "    origin_coords: Tuple[float, float],\n",
        "    destination_coords: Tuple[float, float],\n",
        "    cruising_speed_kmh: Optional[float] = 750.0,  # Average speed for cargo planes\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Calculate the travel time for a cargo plane between two points on Earth using great-circle distance.\n",
        "\n",
        "    Args:\n",
        "        origin_coords: Tuple of (latitude, longitude) for the starting point\n",
        "        destination_coords: Tuple of (latitude, longitude) for the destination\n",
        "        cruising_speed_kmh: Optional cruising speed in km/h (defaults to 750 km/h for typical cargo planes)\n",
        "\n",
        "    Returns:\n",
        "        float: The estimated travel time in hours\n",
        "\n",
        "    Example:\n",
        "        >>> # Chicago (41.8781¬∞ N, 87.6298¬∞ W) to Sydney (33.8688¬∞ S, 151.2093¬∞ E)\n",
        "        >>> result = calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093))\n",
        "    \"\"\"\n",
        "\n",
        "    def to_radians(degrees: float) -> float:\n",
        "        return degrees * (math.pi / 180)\n",
        "\n",
        "    # Extract coordinates\n",
        "    lat1, lon1 = map(to_radians, origin_coords)\n",
        "    lat2, lon2 = map(to_radians, destination_coords)\n",
        "\n",
        "    # Earth's radius in kilometers\n",
        "    EARTH_RADIUS_KM = 6371.0\n",
        "\n",
        "    # Calculate great-circle distance using the haversine formula\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = (\n",
        "        math.sin(dlat / 2) ** 2\n",
        "        + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
        "    )\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "    distance = EARTH_RADIUS_KM * c\n",
        "\n",
        "    # Add 10% to account for non-direct routes and air traffic controls\n",
        "    actual_distance = distance * 1.1\n",
        "\n",
        "    # Calculate flight time\n",
        "    # Add 1 hour for takeoff and landing procedures\n",
        "    flight_time = (actual_distance / cruising_speed_kmh) + 1.0\n",
        "\n",
        "    # Format the results\n",
        "    return round(flight_time, 2)\n",
        "\n",
        "\n",
        "print(calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPgyT9FbavwQ"
      },
      "source": [
        "For the model provider, we use Together AI, one of the new [inference providers on the Hub](https://huggingface.co/blog/inference-providers)!\n",
        "\n",
        "Regarding the GoogleSearchTool: this requires either having setup env variable `SERPAPI_API_KEY` and passing `provider=\"serpapi\"` or having `SERPER_API_KEY` and passing `provider=serper`.\n",
        "\n",
        "If you don't have any Serp API provider setup, you can use `DuckDuckGoSearchTool` but beware that it has a rate limit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw4q7qODavwQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from smolagents import LiteLLMModel, CodeAgent, GoogleSearchTool, HfApiModel, VisitWebpageTool, DuckDuckGoSearchTool\n",
        "\n",
        "\n",
        "model = LiteLLMModel(\n",
        "        model_id=\"ollama_chat/gemma3:4b\", \n",
        "        api_base=\"http://127.0.0.1:11434\",\n",
        "        num_ctx=8192,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6ItyGKtavwR"
      },
      "source": [
        "We can start with creating a baseline, simple agent to give us a simple report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42C3gu75avwR"
      },
      "outputs": [],
      "source": [
        "task = \"\"\"Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128¬∞ N, 74.0060¬∞ W), and return them to me as a pandas dataframe.\n",
        "Also give me some supercar factories with the same cargo plane transfer time.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6ZXgdaGavwS"
      },
      "outputs": [],
      "source": [
        "agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[DuckDuckGoSearchTool(), VisitWebpageTool(), calculate_cargo_travel_time],\n",
        "    additional_authorized_imports=[\"pandas\"],\n",
        "    max_steps=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "apTHCYH1avwT",
        "outputId": "58c631cd-f158-4fe3-c496-adb9624a71d5"
      },
      "outputs": [],
      "source": [
        "result = agent.run(task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "NlgnI2GnavwT",
        "outputId": "2bb30112-f069-4bfe-9155-bcf9216b04a8"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17_UNQk2avwU"
      },
      "source": [
        "We could already improve this a bit by throwing in some dedicated planning steps, and adding more prompting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lzjuyPydavwU",
        "outputId": "55f17151-ffcd-46e0-e04d-39c59065c454"
      },
      "outputs": [],
      "source": [
        "agent.planning_interval = 4\n",
        "\n",
        "detailed_report = agent.run(f\"\"\"\n",
        "You're an expert analyst. You make comprehensive reports after visiting many websites.\n",
        "Don't hesitate to search for many queries at once in a for loop.\n",
        "For each data point that you find, visit the source url to confirm numbers.\n",
        "\n",
        "{task}\n",
        "\"\"\")\n",
        "\n",
        "print(detailed_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "YUAi3P3havwU",
        "outputId": "595d94af-dcb3-49e4-c8c1-81835c23d6aa"
      },
      "outputs": [],
      "source": [
        "detailed_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mYGtUn4avwV"
      },
      "source": [
        "Thanks to these quick changes, we obtained a much more concise report by simply providing our agent a detailed prompt, and giving it planning capabilities!\n",
        "\n",
        "üí∏ But as you can see, the context window is quickly filling up. So **if we ask our agent to combine the results of detailed search with another, it will be slower and quickly ramp up tokens and costs**.\n",
        "\n",
        "‚û°Ô∏è We need to improve the structure of our system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u0StDb0avwV"
      },
      "source": [
        "## ‚úåÔ∏è Splitting the task between two agents\n",
        "\n",
        "Multi-agent structures allow to separate memories between different sub-tasks, with two great benefits:\n",
        "- Each agent is more focused on its core task, thus more performant\n",
        "- Separating memories reduces the count of input tokens at each step, thus reducing latency and cost.\n",
        "\n",
        "Let's create a team with a dedicated web search agent, managed by another agent.\n",
        "\n",
        "The manager agent should have plotting capabilities to redact its final report: so let us give it access to additional imports, including `matplotlib`, and `geopandas` + `shapely` for spatial plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojS5iARCavwV"
      },
      "outputs": [],
      "source": [
        "model = HfApiModel(\n",
        "    \"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"together\", max_tokens=8096\n",
        ")\n",
        "\n",
        "web_agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[\n",
        "        GoogleSearchTool(provider=\"serper\"),\n",
        "        VisitWebpageTool(),\n",
        "        calculate_cargo_travel_time,\n",
        "    ],\n",
        "    name=\"web_agent\",\n",
        "    description=\"Browses the web to find information\",\n",
        "    verbosity_level=0,\n",
        "    max_steps=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAmzCRmkavwV"
      },
      "source": [
        "The manager agent will need to do some mental heavy lifting.\n",
        "\n",
        "So we give it the stronger model [DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1), and add a `planning_interval` to the mix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xLzy0vSCT3W"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqOV5mfuavwW"
      },
      "outputs": [],
      "source": [
        "from smolagents.utils import encode_image_base64, make_image_url\n",
        "from smolagents import OpenAIServerModel\n",
        "\n",
        "\n",
        "def check_reasoning_and_plot(final_answer, agent_memory):\n",
        "    final_answer\n",
        "    multimodal_model = OpenAIServerModel(\"gpt-4o\", max_tokens=8096)\n",
        "    filepath = \"saved_map.png\"\n",
        "    assert os.path.exists(filepath), \"Make sure to save the plot under saved_map.png!\"\n",
        "    image = Image.open(filepath)\n",
        "    prompt = (\n",
        "        f\"Here is a user-given task and the agent steps: {agent_memory.get_succinct_steps()}. Now here is the plot that was made.\"\n",
        "        \"Please check that the reasoning process and plot are correct: do they correctly answer the given task?\"\n",
        "        \"First list reasons why yes/no, then write your final decision: PASS in caps lock if it is satisfactory, FAIL if it is not.\"\n",
        "        \"Don't be harsh: if the plot mostly solves the task, it should pass.\"\n",
        "        \"To pass, a plot should be made using px.scatter_map and not any other method (scatter_map looks nicer).\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": prompt,\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": make_image_url(encode_image_base64(image))},\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "    output = multimodal_model(messages).content\n",
        "    print(\"Feedback: \", output)\n",
        "    if \"FAIL\" in output:\n",
        "        raise Exception(output)\n",
        "    return True\n",
        "\n",
        "\n",
        "manager_agent = CodeAgent(\n",
        "    model=HfApiModel(\"deepseek-ai/DeepSeek-R1\", provider=\"together\", max_tokens=8096),\n",
        "    tools=[calculate_cargo_travel_time],\n",
        "    managed_agents=[web_agent],\n",
        "    additional_authorized_imports=[\n",
        "        \"geopandas\",\n",
        "        \"plotly\",\n",
        "        \"shapely\",\n",
        "        \"json\",\n",
        "        \"pandas\",\n",
        "        \"numpy\",\n",
        "    ],\n",
        "    planning_interval=5,\n",
        "    verbosity_level=2,\n",
        "    final_answer_checks=[check_reasoning_and_plot],\n",
        "    max_steps=15,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9ZX-xdvavwW"
      },
      "source": [
        "Let us inspect what this team looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jEWXBr-avwW",
        "outputId": "95a73510-026d-47f6-972a-e72ad94060ac"
      },
      "outputs": [],
      "source": [
        "manager_agent.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyGu4VylavwW",
        "outputId": "220b8c08-f5a6-4c41-eaf3-d684ee773a85"
      },
      "outputs": [],
      "source": [
        "manager_agent.run(\"\"\"\n",
        "Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128¬∞ N, 74.0060¬∞ W).\n",
        "Also give me some supercar factories with the same cargo plane transfer time. You need at least 6 points in total.\n",
        "Represent this as spatial map of the world, with the locations represented as scatter points with a color that depends on the travel time, and save it to saved_map.png!\n",
        "\n",
        "Here's an example of how to plot and return a map:\n",
        "import plotly.express as px\n",
        "df = px.data.carshare()\n",
        "fig = px.scatter_map(df, lat=\"centroid_lat\", lon=\"centroid_lon\", text=\"name\", color=\"peak_hour\", size=100,\n",
        "     color_continuous_scale=px.colors.sequential.Magma, size_max=15, zoom=1)\n",
        "fig.show()\n",
        "fig.write_image(\"saved_image.png\")\n",
        "final_answer(fig)\n",
        "\n",
        "Never try to process strings using code: when you have a string to read, just print it and you'll see it.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGuNy8RJavwX"
      },
      "source": [
        "I don't know how that went in your run, but in mine, the manager agent skilfully divided tasks given to the web agent in `1. Search for Batman filming locations`, then `2. Find supercar factories`, before aggregating the lists and plotting the map.\n",
        "\n",
        "Let's see what the map looks like by inspecting it directly from the agent state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0lADQ18avwX",
        "outputId": "0685ac3c-4b9f-4f62-f33e-d81545c365b2"
      },
      "outputs": [],
      "source": [
        "manager_agent.python_executor.state[\"fig\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzD9OxdVavwY"
      },
      "source": [
        "![output map](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/smolagents/output_map.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cv-utu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
